{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c1fa78",
   "metadata": {},
   "source": [
    "# Get the embedding model\n",
    "\n",
    "https://qdrant.tech/documentation/fastembed/fastembed-colbert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc56a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import LateInteractionTextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3a410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colbert-ir/colbertv2.0\n",
      "answerdotai/answerai-colbert-small-v1\n",
      "jinaai/jina-colbert-v2\n"
     ]
    }
   ],
   "source": [
    "for model in LateInteractionTextEmbedding.list_supported_models():\n",
    "    print(model['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b9dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"colbert-ir/colbertv2.0\"\n",
    "embedding_model = LateInteractionTextEmbedding(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60dcdc3",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1f9ed2",
   "metadata": {},
   "source": [
    "### Convert pdf to markdown using docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06570dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:17:09,798 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-14 01:17:09,874 - INFO - Going to convert document batch...\n",
      "2025-09-14 01:17:09,876 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e647edf348883bed75367b22fbe60347\n",
      "2025-09-14 01:17:09,892 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-09-14 01:17:09,895 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-09-14 01:17:09,912 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-09-14 01:17:09,917 - INFO - Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-09-14 01:17:10,094 - INFO - Accelerator device: 'cuda:0'\n",
      "/home/hoang.hung.manh/test_everything/late_interaction_retriever/.venv/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:38: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(\n",
      "2025-09-14 01:17:12,798 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-09-14 01:17:14,226 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-09-14 01:17:14,921 - INFO - Processing document 2408.09869v5.pdf\n",
      "2025-09-14 01:17:31,555 - INFO - Finished converting document 2408.09869v5.pdf in 56.81 sec.\n",
      "2025-09-14 01:17:32,108 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-14 01:17:32,127 - INFO - Going to convert document batch...\n",
      "2025-09-14 01:17:32,129 - INFO - Processing document 2509.04664v1.pdf\n",
      "2025-09-14 01:17:49,978 - INFO - Finished converting document 2509.04664v1.pdf in 18.37 sec.\n",
      "2025-09-14 01:17:50,453 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-14 01:17:50,459 - INFO - Going to convert document batch...\n",
      "2025-09-14 01:17:50,460 - INFO - Processing document 2505.09388v1.pdf\n",
      "2025-09-14 01:18:48,377 - INFO - Finished converting document 2505.09388v1.pdf in 58.33 sec.\n",
      "2025-09-14 01:18:48,946 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-09-14 01:18:48,974 - INFO - Going to convert document batch...\n",
      "2025-09-14 01:18:48,976 - INFO - Processing document 2506.05176v3.pdf\n",
      "2025-09-14 01:19:03,285 - INFO - Finished converting document 2506.05176v3.pdf in 14.77 sec.\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "sources = [\n",
    "    \"https://arxiv.org/pdf/2408.09869\",\n",
    "    \"https://www.arxiv.org/pdf/2509.04664\",\n",
    "    \"https://arxiv.org/pdf/2505.09388\",\n",
    "    \"https://arxiv.org/pdf/2506.05176\"\n",
    "]\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "results_parsed = []\n",
    "for source in sources:\n",
    "    result = converter.convert(source)\n",
    "    results_parsed.append(result.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c9ec3",
   "metadata": {},
   "source": [
    "### Chunking using chonkie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e519d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:19:03,409 - INFO - Folder does not exist locally, attempting to use huggingface hub.\n"
     ]
    }
   ],
   "source": [
    "from chonkie import SemanticChunker\n",
    "\n",
    "# Basic initialization with default parameters\n",
    "chunker = SemanticChunker(\n",
    "    embedding_model=\"minishlab/potion-base-32M\",  # Default model\n",
    "    threshold=0.8,                               # Similarity threshold (0-1)\n",
    "    chunk_size=1024,                             # Maximum tokens per chunk\n",
    "    similarity_window=3,                         # Window for similarity calculation\n",
    "    skip_window=0                                # Skip-and-merge window (0=disabled)\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for doc in results_parsed:\n",
    "    doc_chunks = chunker.chunk(doc)\n",
    "    chunks.append(doc_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32587c9",
   "metadata": {},
   "source": [
    "## Connect to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f6d3f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:19:07,330 - INFO - HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b85ef",
   "metadata": {},
   "source": [
    "### Create a collection if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85e7dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:19:07,344 - INFO - HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collections().collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857f0bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:19:07,355 - INFO - HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:19:07,404 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.http import models\n",
    "\n",
    "collection_name = \"test_multivector\"\n",
    "\n",
    "# Create a collection if it does not exist\n",
    "if collection_name not in client.get_collections().collections:\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=128,\n",
    "            distance=models.Distance.COSINE,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM\n",
    "            )\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e7cdb",
   "metadata": {},
   "source": [
    "### Embed data using multi-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17764ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [\n",
    "    {\"document_name\" : \"Docling Technical Report\"},\n",
    "    {\"document_name\" : \"Why Language Models Hallucinate\"},\n",
    "    {\"document_name\" : \"Qwen 3 Technical Report\"},\n",
    "    {\"document_name\" : \"Qwen 3 Embedding Technical Report\"} \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a73ffbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata = []\n",
    "for i, doc_chunks in enumerate(chunks):\n",
    "    for chunk in doc_chunks:\n",
    "        new_metadata.append({\n",
    "            \"document_name\": metadata[i][\"document_name\"],\n",
    "            \"text\": chunk.text,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e30ca924",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_texts = [chunk.text for doc_chunks in chunks for chunk in doc_chunks]\n",
    "\n",
    "chunks_embedding = list(\n",
    "    embedding_model.embed(chunk_texts)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe76bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:24:24,831 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:25,070 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:25,412 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:25,733 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:25,904 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:26,064 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:26,281 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:26,569 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:26,875 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:27,108 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:27,338 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:27,747 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:28,016 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:28,357 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:28,696 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:24:29,043 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_multivector/points?wait=false \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "client.upload_points(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx,\n",
    "            payload=new_metadata[idx],\n",
    "            vector=vector\n",
    "        )\n",
    "        for idx, vector in enumerate(chunks_embedding)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f722f1b",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "297b151b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:24:29,116 - INFO - HTTP Request: POST http://localhost:6333/collections/test_multivector/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QueryResponse(points=[ScoredPoint(id=373, version=5, score=23.378906, payload={'document_name': 'Why Language Models Hallucinate', 'text': '- Yiyou Sun, Yu Gai, Lijie Chen, Abhilasha Ravichander, Yejin Choi, and Dawn Song. 2025. Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations. https: //doi.org/10.48550/arXiv.2504.12691 arXiv:2504.12691 [cs.CL]\\n- Mirac Suzgun, Nathan Scales, Nathanael Sch¨ arli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. '}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=272, version=4, score=18.774275, payload={'document_name': 'Why Language Models Hallucinate', 'text': '2024. Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?. '}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=109, version=1, score=18.587532, payload={'document_name': 'Why Language Models Hallucinate', 'text': \"\\nLike students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such 'hallucinations' persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious-they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded-language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This 'epidemic' of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. \"}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=285, version=4, score=18.473633, payload={'document_name': 'Why Language Models Hallucinate', 'text': '4. Giwon Hong, Aryo Pradipta Gema, Rohit Saxena, Xiaotang Du, Ping Nie, Yu Zhao, Laura PerezBeltrachini, Max Ryabinin, Xuanli He, Cl´ ementine Fourrier, and Pasquale Minervini. 2024. The Hallucinations Leaderboard - An Open Effort to Measure Hallucinations in Large Language Models. arXiv:2404.05904 [cs.CL] https://arxiv.org/abs/2404.05904\\n5. Hugging Face. 2024. Open LLM Leaderboard v2 Collection. https://huggingface.co/spaces/ open-llm-leaderboard/blog . Accessed: 26 June 2025.\\n'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=115, version=1, score=18.196312, payload={'document_name': 'Why Language Models Hallucinate', 'text': '\\nHallucinations are an important special case of errors produced by language models, which we analyze more generally using computational learning theory (e.g., Kearns and Vazirani, 1994). We consider general sets of errors E , an arbitrary subset of plausible strings X = E ∪ V , with the other plausible strings V being called valid . We then analyze the statistical nature of these errors, and\\n'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=232, version=3, score=17.118042, payload={'document_name': 'Why Language Models Hallucinate', 'text': '\\nPlausibility and nonsense. A hallucination is a plausible falsehood, and by considering only plausible strings X , our analysis ignores the possibility of generating nonsensical strings (which state-of-the-art language models rarely generate). However, the statement and proof of Theorem 1 hold with the modified definitions of nonsensical examples N with partition X = N ∪ E ∪ V , err := ˆ p ( N ∪ E ), D ( N ) = 0, and the assumption that p ( V ) = 1.\\n'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=136, version=2, score=16.243593, payload={'document_name': 'Why Language Models Hallucinate', 'text': '\\n## 1.2 Why hallucinations survive post-training\\n'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=148, version=2, score=16.001463, payload={'document_name': 'Why Language Models Hallucinate', 'text': '\\nA number of surveys and studies have explored the underlying causes of hallucination in language models. Sun et al. (2025) cite factors such as model overconfidence Yin et al. (2023), decoding randomness Lee et al. (2022), snowballing effects Zhang et al. (2023), long-tailed training samples Sun et al. (2023), misleading alignment training Wei et al. (2023), spurious correlations Li et al. (2022), exposure bias Bengio et al. '}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=248, version=3, score=15.812827, payload={'document_name': 'Why Language Models Hallucinate', 'text': 'Edited by J. O. Urmson and Marina Sbis` a.\\n- Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. 2022. Constitutional AI: Harmlessness from AI Feedback. arXiv:2212.08073 [cs.CL] https://arxiv.org/abs/2212.08073\\n- Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, and Pascale Fung. 2025. HalluLens: LLM Hallucination Benchmark. '}, vector=None, shard_key=None, order_value=None), ScoredPoint(id=111, version=1, score=15.611437, payload={'document_name': 'Why Language Models Hallucinate', 'text': \"\\n## 1 Introduction\\n\\nLanguage models are known to produce overconfident, plausible falsehoods, which diminish their utility and trustworthiness. This error mode is known as 'hallucination,' though it differs fundamentally from the human perceptual experience. Despite significant progress, hallucinations continue to plague the field, and are still present in the latest models (OpenAI, 2025a). \"}, vector=None, shard_key=None, order_value=None)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=list(embedding_model.query_embed(\"why llm hallucinate\"))[0], #converting generator object into numpy.ndarray\n",
    "    limit=10, #How many closest to the query movies we would like to get\n",
    "    #with_vectors=True, #If this option is used, vectors will also be returned\n",
    "    with_payload=True #So metadata is provided in the output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2122aa2",
   "metadata": {},
   "source": [
    "## Embed single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1b44d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:36:17,311 - INFO - Use pytorch device_name: cuda:0\n",
      "2025-09-14 01:36:17,312 - INFO - Load pretrained SentenceTransformer: Qwen/Qwen3-Embedding-0.6B\n",
      "2025-09-14 01:36:24,644 - INFO - 1 prompt is loaded, with the key: query\n",
      "Batches: 100%|██████████| 32/32 [00:07<00:00,  4.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Requires transformers>=4.51.0\n",
    "# Requires sentence-transformers>=2.7.0\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "\n",
    "document_embeddings = model.encode(chunk_texts, prompt_name='document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e6b74dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery:',\n",
       " 'document': ''}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8668355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:36:48,396 - INFO - HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:48,443 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.http import models\n",
    "\n",
    "collection_name = \"test_single_vector\"\n",
    "\n",
    "# Create a collection if it does not exist\n",
    "if collection_name not in client.get_collections().collections:\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=1024,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ef3787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:36:54,215 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,262 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,314 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,376 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,438 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,509 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,579 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,648 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,711 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,749 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,779 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,834 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,893 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:54,962 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:55,016 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n",
      "2025-09-14 01:36:55,069 - INFO - HTTP Request: PUT http://localhost:6333/collections/test_single_vector/points?wait=false \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "client.upload_points(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx,\n",
    "            payload=new_metadata[idx],\n",
    "            vector=vector\n",
    "        )\n",
    "        for idx, vector in enumerate(document_embeddings)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4f03dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s]\n",
      "2025-09-14 01:38:23,136 - INFO - HTTP Request: POST http://localhost:6333/collections/test_single_vector/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "retrieved = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=model.encode(\"why llm hallucinate\", prompt_name='query'), #converting generator object into numpy.ndarray\n",
    "    limit=10, #How many closest to the query movies we would like to get\n",
    "    #with_vectors=True, #If this option is used, vectors will also be returned\n",
    "    with_payload=True #So metadata is provided in the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62caed21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qdrant_client.http.models.models.QueryResponse"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a90a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Why Language Models Hallucinate\n",
      "\n",
      "Adam Tauman Kalai ∗ OpenAI\n",
      "\n",
      "Ofir Nachum OpenAI\n",
      "\n",
      "Santosh S. Vempala † Georgia Tech\n",
      "\n",
      "\n",
      "-------------\n",
      "\n",
      "Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such 'hallucinations' persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious-they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded-language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This 'epidemic' of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. \n",
      "-------------\n",
      "- Yiyou Sun, Yu Gai, Lijie Chen, Abhilasha Ravichander, Yejin Choi, and Dawn Song. 2025. Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations. https: //doi.org/10.48550/arXiv.2504.12691 arXiv:2504.12691 [cs.CL]\n",
      "- Mirac Suzgun, Nathan Scales, Nathanael Sch¨ arli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. \n",
      "-------------\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Language models are known to produce overconfident, plausible falsehoods, which diminish their utility and trustworthiness. This error mode is known as 'hallucination,' though it differs fundamentally from the human perceptual experience. Despite significant progress, hallucinations continue to plague the field, and are still present in the latest models (OpenAI, 2025a). \n",
      "-------------\n",
      "2024. Hallucination is Inevitable: An Innate Limitation of Large Language Models. arXiv:2401.11817 [cs.CL] https://arxiv.org/abs/2401. \n",
      "-------------\n",
      "\n",
      "apply the results for the type of errors of interest: plausible falsehoods called hallucinations. Our formalism also includes the notion of a prompt to which a language model must respond.\n",
      "\n",
      "Our error analysis is general yet has specific implications for hallucination. It applies broadly, including to reasoning and search-and-retrieval language models, and the analysis does not rely on properties of next-word prediction or Transformer-based neural networks. \n",
      "-------------\n",
      "\n",
      "A number of surveys and studies have explored the underlying causes of hallucination in language models. Sun et al. (2025) cite factors such as model overconfidence Yin et al. (2023), decoding randomness Lee et al. (2022), snowballing effects Zhang et al. (2023), long-tailed training samples Sun et al. (2023), misleading alignment training Wei et al. (2023), spurious correlations Li et al. (2022), exposure bias Bengio et al. \n",
      "-------------\n",
      "A number of studies have shown how language models augmented with search or Retrieval-Augmented Generation (RAG) reduce hallucinations (Lewis et al., 2020; Shuster et al., 2021; Nakano et al., 2021; Zhang and Zhang, 2025). \n",
      "-------------\n",
      "- Muru Zhang, Ofir Press, William Merrill, Alisa Liu, and Noah A Smith. 2023. How Language Model Hallucinations Can Snowball. arXiv:2305.13534 [cs.CL] https://arxiv.org/abs/2305.13534\n",
      "- Wan Zhang and Jing Zhang. \n",
      "-------------\n",
      "2024. Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?. \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for point in retrieved.points:\n",
    "    print(point.payload['text'])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "810153ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:40:59,164 - INFO - HTTP Request: POST http://localhost:6333/collections/test_multivector/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "retrieved_multivec = client.query_points(\n",
    "    collection_name=\"test_multivector\",\n",
    "    query=list(embedding_model.query_embed(\"why llm hallucinate\"))[0], #converting generator object into numpy.ndarray\n",
    "    limit=10, #How many closest to the query movies we would like to get\n",
    "    #with_vectors=True, #If this option is used, vectors will also be returned\n",
    "    with_payload=True #So metadata is provided in the output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c06c780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Yiyou Sun, Yu Gai, Lijie Chen, Abhilasha Ravichander, Yejin Choi, and Dawn Song. 2025. Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations. https: //doi.org/10.48550/arXiv.2504.12691 arXiv:2504.12691 [cs.CL]\n",
      "- Mirac Suzgun, Nathan Scales, Nathanael Sch¨ arli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed H. Chi, Denny Zhou, and Jason Wei. \n",
      "-------------\n",
      "2024. Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?. \n",
      "-------------\n",
      "\n",
      "Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such 'hallucinations' persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious-they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded-language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This 'epidemic' of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. \n",
      "-------------\n",
      "4. Giwon Hong, Aryo Pradipta Gema, Rohit Saxena, Xiaotang Du, Ping Nie, Yu Zhao, Laura PerezBeltrachini, Max Ryabinin, Xuanli He, Cl´ ementine Fourrier, and Pasquale Minervini. 2024. The Hallucinations Leaderboard - An Open Effort to Measure Hallucinations in Large Language Models. arXiv:2404.05904 [cs.CL] https://arxiv.org/abs/2404.05904\n",
      "5. Hugging Face. 2024. Open LLM Leaderboard v2 Collection. https://huggingface.co/spaces/ open-llm-leaderboard/blog . Accessed: 26 June 2025.\n",
      "\n",
      "-------------\n",
      "\n",
      "Hallucinations are an important special case of errors produced by language models, which we analyze more generally using computational learning theory (e.g., Kearns and Vazirani, 1994). We consider general sets of errors E , an arbitrary subset of plausible strings X = E ∪ V , with the other plausible strings V being called valid . We then analyze the statistical nature of these errors, and\n",
      "\n",
      "-------------\n",
      "\n",
      "Plausibility and nonsense. A hallucination is a plausible falsehood, and by considering only plausible strings X , our analysis ignores the possibility of generating nonsensical strings (which state-of-the-art language models rarely generate). However, the statement and proof of Theorem 1 hold with the modified definitions of nonsensical examples N with partition X = N ∪ E ∪ V , err := ˆ p ( N ∪ E ), D ( N ) = 0, and the assumption that p ( V ) = 1.\n",
      "\n",
      "-------------\n",
      "\n",
      "## 1.2 Why hallucinations survive post-training\n",
      "\n",
      "-------------\n",
      "\n",
      "A number of surveys and studies have explored the underlying causes of hallucination in language models. Sun et al. (2025) cite factors such as model overconfidence Yin et al. (2023), decoding randomness Lee et al. (2022), snowballing effects Zhang et al. (2023), long-tailed training samples Sun et al. (2023), misleading alignment training Wei et al. (2023), spurious correlations Li et al. (2022), exposure bias Bengio et al. \n",
      "-------------\n",
      "Edited by J. O. Urmson and Marina Sbis` a.\n",
      "- Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. 2022. Constitutional AI: Harmlessness from AI Feedback. arXiv:2212.08073 [cs.CL] https://arxiv.org/abs/2212.08073\n",
      "- Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, and Pascale Fung. 2025. HalluLens: LLM Hallucination Benchmark. \n",
      "-------------\n",
      "\n",
      "## 1 Introduction\n",
      "\n",
      "Language models are known to produce overconfident, plausible falsehoods, which diminish their utility and trustworthiness. This error mode is known as 'hallucination,' though it differs fundamentally from the human perceptual experience. Despite significant progress, hallucinations continue to plague the field, and are still present in the latest models (OpenAI, 2025a). \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for point in retrieved_multivec.points:\n",
    "    print(point.payload['text'])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23752137",
   "metadata": {},
   "source": [
    "## Check size of 2 collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83b0997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:43:18,630 - INFO - HTTP Request: GET http://localhost:6333/collections/test_single_vector \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=1000 segments_count=8 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1024, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=10000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=StrictModeConfigOutput(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None)) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "info = client.get_collection(\"test_single_vector\")\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b64d951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 01:43:28,559 - INFO - HTTP Request: GET http://localhost:6333/collections/test_multivector \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=1000 segments_count=8 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=128, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=MultiVectorConfig(comparator=<MultiVectorComparator.MAX_SIM: 'max_sim'>)), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=10000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=StrictModeConfigOutput(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None)) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "info = client.get_collection(\"test_multivector\")\n",
    "\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d93bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "late-interaction-retriever",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
